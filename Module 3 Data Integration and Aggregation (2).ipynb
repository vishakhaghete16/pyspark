{"cells": [{"cell_type": "code", "execution_count": 1, "id": "a51c3115-e295-4dfb-b4cb-1d08d789fc03", "metadata": {"tags": []}, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-c8a4-m.c.eng-lightning-456602-c1.internal:33949\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7fd0a9012690>"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "spark"}, {"cell_type": "code", "execution_count": 2, "id": "85e54ba1-e1c9-49a9-85d7-4aa803622f15", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/16 16:25:19 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n.appName('OlistData')\\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "id": "0955bcb1-b599-4768-9bc2-d383ce7f1c68", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/16 16:25:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:25:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\nERROR:root:KeyboardInterrupt while sending command.\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n    response = connection.send_command(command)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n    answer = smart_decode(self.stream.readline()[:-1])\n                          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/miniconda3/lib/python3.11/socket.py\", line 706, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n"}, {"ename": "KeyboardInterrupt", "evalue": "", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m customer_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/olist/olist_customers_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43minferSchema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m geolocation_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/olist/olist_geolocation_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,inferSchema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m order_item_df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/olist/olist_order_items_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,inferSchema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc\u001b[39m(iterator):\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}, {"name": "stderr", "output_type": "stream", "text": "25/04/16 16:26:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:26:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:26:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:26:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:27:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:27:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:27:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:27:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:28:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:28:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:28:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:28:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:29:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:29:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:29:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:29:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:30:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:30:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:30:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:30:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:31:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:31:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:31:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:31:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:32:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:32:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:32:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:32:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:33:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:33:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:33:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:33:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:34:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:34:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:34:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:34:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:35:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:35:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:35:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:35:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:36:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:36:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:36:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:36:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:37:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:37:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:37:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:37:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:38:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:38:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:38:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:38:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:39:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:39:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:39:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:39:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:40:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:40:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:40:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:40:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:41:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:41:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:41:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:41:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:42:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:42:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:42:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:42:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:43:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:43:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:43:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:43:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:44:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:44:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:44:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:44:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:45:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:45:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:45:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:45:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:46:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:46:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:46:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:46:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:47:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:47:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:47:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:47:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:48:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:48:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:48:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:48:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:49:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:49:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:49:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:49:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:50:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:50:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:50:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:50:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:51:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:51:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:51:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:51:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:52:13 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:52:28 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:52:43 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n25/04/16 16:52:58 WARN YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n"}], "source": "customer_df = spark.read.csv('/data/olist/olist_customers_dataset.csv',header=True,inferSchema=True)\ngeolocation_df = spark.read.csv('/data/olist/olist_geolocation_dataset.csv',header=True,inferSchema=True)\norder_item_df = spark.read.csv('/data/olist/olist_order_items_dataset.csv',header=True,inferSchema=True)\npayment_df = spark.read.csv('/data/olist/olist_order_payments_dataset.csv',header=True,inferSchema=True)\nreview_df = spark.read.csv('/data/olist/olist_order_reviews_dataset.csv',header=True,inferSchema=True)\norder_df = spark.read.csv('/data/olist/olist_orders_dataset.csv',header=True,inferSchema=True)\nproduct_df = spark.read.csv('/data/olist/olist_products_dataset.csv',header=True,inferSchema=True)\nseller_df = spark.read.csv('/data/olist/olist_sellers_dataset.csv',header=True,inferSchema=True)\ncategory_translation_df = spark.read.csv('/data/olist/product_category_name_translation.csv',header=True,inferSchema=True)"}, {"cell_type": "code", "execution_count": 32, "id": "6c005d99-024d-40c2-995d-eb89157ffb81", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/04/16 10:54:58 WARN CacheManager: Asked to cache already cached data.\n25/04/16 10:54:58 WARN CacheManager: Asked to cache already cached data.\n25/04/16 10:54:58 WARN CacheManager: Asked to cache already cached data.\n"}, {"data": {"text/plain": "DataFrame[order_id: string, order_item_id: int, product_id: string, seller_id: string, shipping_limit_date: timestamp, price: double, freight_value: double]"}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}], "source": "# cache frequanlty  used data for better performance\norder_df.cache()\ncustomer_df.cache()\norder_item_df.cache()"}, {"cell_type": "code", "execution_count": 7, "id": "fe155826-e7fe-4425-83ae-1e99a2e01eb6", "metadata": {"tags": []}, "outputs": [], "source": "order_item_join_df = order_df.join(order_item_df,'order_id','inner')\norder_item_product_df = order_item_join_df.join(product_df,'product_id','inner')\norder_item_products_seller_df = order_item_product_df.join(seller_df , 'seller_id' , 'inner')\n"}, {"cell_type": "code", "execution_count": null, "id": "7c28748f-6b71-486c-935c-2b68488cd4f0", "metadata": {"tags": []}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 8, "id": "1790089c-d9d8-4282-805f-f746286737db", "metadata": {"tags": []}, "outputs": [], "source": "full_order_df = order_item_products_seller_df.join(customer_df,'customer_id','inner')"}, {"cell_type": "code", "execution_count": 10, "id": "b21541fe-b14b-4168-aae9-521eb94268cc", "metadata": {"tags": []}, "outputs": [], "source": "full_order_df = full_order_df.join(geolocation_df,full_order_df.customer_zip_code_prefix == geolocation_df.geolocation_zip_code_prefix,'left')"}, {"cell_type": "code", "execution_count": 12, "id": "604eaaa0-90ec-4bea-996a-097c15970132", "metadata": {"tags": []}, "outputs": [], "source": "full_order_df = full_order_df.join(review_df,'order_id','left')\n"}, {"cell_type": "code", "execution_count": 14, "id": "beba274e-b53d-4fb3-bd01-56e525186a12", "metadata": {"tags": []}, "outputs": [], "source": "full_order_df = full_order_df.join(payment_df,'order_id','left')"}, {"cell_type": "code", "execution_count": 15, "id": "cf24d477-c6a5-40b5-b6bb-1ec29d8d7580", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- order_id: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- seller_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n |-- order_purchase_timestamp: timestamp (nullable = true)\n |-- order_approved_at: timestamp (nullable = true)\n |-- order_delivered_carrier_date: timestamp (nullable = true)\n |-- order_delivered_customer_date: timestamp (nullable = true)\n |-- order_estimated_delivery_date: timestamp (nullable = true)\n |-- order_item_id: integer (nullable = true)\n |-- shipping_limit_date: timestamp (nullable = true)\n |-- price: double (nullable = true)\n |-- freight_value: double (nullable = true)\n |-- product_category_name: string (nullable = true)\n |-- product_name_lenght: integer (nullable = true)\n |-- product_description_lenght: integer (nullable = true)\n |-- product_photos_qty: integer (nullable = true)\n |-- product_weight_g: integer (nullable = true)\n |-- product_length_cm: integer (nullable = true)\n |-- product_height_cm: integer (nullable = true)\n |-- product_width_cm: integer (nullable = true)\n |-- seller_zip_code_prefix: integer (nullable = true)\n |-- seller_city: string (nullable = true)\n |-- seller_state: string (nullable = true)\n |-- customer_unique_id: string (nullable = true)\n |-- customer_zip_code_prefix: integer (nullable = true)\n |-- customer_city: string (nullable = true)\n |-- customer_state: string (nullable = true)\n |-- geolocation_zip_code_prefix: integer (nullable = true)\n |-- geolocation_lat: double (nullable = true)\n |-- geolocation_lng: double (nullable = true)\n |-- geolocation_city: string (nullable = true)\n |-- geolocation_state: string (nullable = true)\n |-- review_id: string (nullable = true)\n |-- review_score: string (nullable = true)\n |-- review_comment_title: string (nullable = true)\n |-- review_comment_message: string (nullable = true)\n |-- review_creation_date: string (nullable = true)\n |-- review_answer_timestamp: string (nullable = true)\n |-- payment_sequential: integer (nullable = true)\n |-- payment_type: string (nullable = true)\n |-- payment_installments: integer (nullable = true)\n |-- payment_value: double (nullable = true)\n\n"}], "source": "full_order_df.printSchema"}, {"cell_type": "code", "execution_count": 23, "id": "cf767b39-6e83-4287-b9f3-317c74106037", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql.functions import *"}, {"cell_type": "code", "execution_count": 18, "id": "4542f314-c27c-44e2-abbc-1923068db100", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "18064261"}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": "full_order_df.count()"}, {"cell_type": "code", "execution_count": null, "id": "5a703a43-c0b1-4b07-ab60-11e69be3657b", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "1e932146-84f7-4522-a52b-68a690d75b04", "metadata": {"tags": []}, "source": "# total revenues per seller"}, {"cell_type": "code", "execution_count": 24, "id": "2913ab9e-2940-4bd0-b6a9-1ce316ab73ed", "metadata": {"tags": []}, "outputs": [], "source": "seller_revenue_df = full_order_df.groupBy('seller_id').agg(sum('price'))"}, {"cell_type": "code", "execution_count": 25, "id": "b1655570-3deb-42e8-8090-d3eacfc62a0c", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 41:====================================================>(987 + 2) / 1000]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+------------------+\n|           seller_id|        sum(price)|\n+--------------------+------------------+\n|3d5d0dc7073a299e3...|          170639.6|\n|2138ccb85b11a4ec1...| 1943866.069999998|\n|d650b663c3b5f6fb3...|         2253869.1|\n|cd06602b43d8800bd...| 353150.9800000004|\n|3c487ae8f8d7542be...|1618845.7000000055|\n+--------------------+------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "seller_revenue_df.show(5)"}, {"cell_type": "code", "execution_count": 30, "id": "04277548-68b9-47c5-b15c-8f9590941ed6", "metadata": {"tags": []}, "outputs": [], "source": "most_sold_product = full_order_df.groupBy('product_category_name').agg(count('product_id'))"}, {"cell_type": "code", "execution_count": 31, "id": "68838e84-c794-4e7f-bca7-6bd7644f1bf8", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 58:====================================================>(991 + 2) / 1000]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------------------+-----------------+\n|product_category_name|count(product_id)|\n+---------------------+-----------------+\n|           perfumaria|           539288|\n|       consoles_games|           180691|\n+---------------------+-----------------+\nonly showing top 2 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "most_sold_product.show(2)"}, {"cell_type": "code", "execution_count": null, "id": "75777de8-a82a-4c6d-bb82-df06f47cd4f8", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 39, "id": "c6b9b732-0ef7-477b-96f6-7c92e4259473", "metadata": {"tags": []}, "outputs": [], "source": "# total order per customer\n\ncustomer_order_count_df = full_order_df.groupBy('customer_id')\\\n.agg(count('order_id').alias('total_order'))\\\n.orderBy(desc('total_order'))"}, {"cell_type": "code", "execution_count": 40, "id": "bf542f3a-09c8-48a6-898a-04e94af17f13", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 79:====================================================>(993 + 2) / 1000]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-----------+\n|         customer_id|total_order|\n+--------------------+-----------+\n|351e40989da90e704...|      11427|\n+--------------------+-----------+\nonly showing top 1 row\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "customer_order_count_df.show(1)"}, {"cell_type": "code", "execution_count": 41, "id": "53fe472f-8ac5-4653-ac80-320df85f8721", "metadata": {"tags": []}, "outputs": [], "source": "# average review score per seller\nseller_reviev_df = full_order_df.groupBy('seller_id')\\\n.agg(avg('review_score').alias('avg_review_score'))\\\n.orderBy(desc('avg_review_score'))"}, {"cell_type": "code", "execution_count": 42, "id": "6fb81ca6-420f-4178-9d94-47798d99dbba", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 86:====================================================>(989 + 2) / 1000]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+----------------+\n|           seller_id|avg_review_score|\n+--------------------+----------------+\n|228e4c1a0be164f61...|             5.0|\n+--------------------+----------------+\nonly showing top 1 row\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "seller_reviev_df.show(1)"}, {"cell_type": "code", "execution_count": 46, "id": "27a56af4-60f8-44a9-8330-820918555a2f", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 100:===================================================>(982 + 2) / 1000]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+----------------+\n|          product_id|top_sold_product|\n+--------------------+----------------+\n|aca2eb7d00ea1a7b8...|           86740|\n+--------------------+----------------+\nonly showing top 1 row\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# top 10 most sold product\ntop_product_df = full_order_df.groupBy('product_id')\\\n.agg(count('order_id').alias('top_sold_product'))\\\n.orderBy(desc('top_sold_product'))\ntop_product_df.show(1)"}, {"cell_type": "code", "execution_count": null, "id": "02e72aa4-0657-4d2c-bdea-49f4ffeb7d7c", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "markdown", "id": "13064f3d-315d-439c-aa77-0d4a1022f068", "metadata": {"tags": []}, "source": "# windows function and ranking"}, {"cell_type": "code", "execution_count": 47, "id": "38b35026-6bcb-4ff8-8578-4ae42c719154", "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql.window import Window"}, {"cell_type": "code", "execution_count": 49, "id": "d42c0b74-1817-4706-9a10-188315b106cc", "metadata": {"tags": []}, "outputs": [], "source": "# dense rank for seller based on revenue\n\nwindow_spec = Window.partitionBy('seller_id').orderBy(desc('price'))"}, {"cell_type": "code", "execution_count": 52, "id": "309f03ea-259a-4841-aa36-9ad5969d57a2", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 111:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-----+----+\n|           seller_id|price|rank|\n+--------------------+-----+----+\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n|0015a82c2db000af6...|895.0|   1|\n+--------------------+-----+----+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# rank top selling product per seller\n\ntop_selling_product_df = full_order_df.withColumn('rank',rank().over(window_spec)).filter(col('rank') <= 5)\ntop_selling_product_df.select('seller_id','price','rank').show()"}, {"cell_type": "markdown", "id": "9ec5de6c-b631-4e08-bb8f-6142d530033e", "metadata": {}, "source": "<!-- advance aggregation and enrichment -->"}, {"cell_type": "markdown", "id": "b5fcc885-d796-403c-a5cf-ff3da9b693ae", "metadata": {}, "source": ""}, {"cell_type": "markdown", "id": "fd32e674-888d-4ba4-94a9-6c29571b5e15", "metadata": {}, "source": "#  advance aggregation and enrichment  "}, {"cell_type": "code", "execution_count": 53, "id": "6f5f3b33-9f1f-4a11-944a-8bbdbab94ec9", "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 114:===================================================>(992 + 2) / 1000]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+------------+-----------+------+\n|         customer_id|total_orders|total_spend|   AOV|\n+--------------------+------------+-----------+------+\n|d3e82ccec3cb5f956...|        6876|  6662844.0| 969.0|\n|df55c14d1476a9a34...|         743|  3565657.0|4799.0|\n+--------------------+------------+-----------+------+\nonly showing top 2 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# total revenue and avrage order value(aov) per customer\n\ncustomer_spending_df = full_order_df.groupBy('customer_id')\\\n.agg(\n    count('order_id').alias('total_orders'),\n    sum('price').alias('total_spend'),\n    round(avg('price'),2).alias('AOV')\n)\\\n.orderBy(desc('total_spend'))\n\ncustomer_spending_df.show(2)"}, {"cell_type": "code", "execution_count": null, "id": "e5c70ec6-4d63-4fc2-a2ed-16a7245035e5", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 5}